name: AI PR Review

on:
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  ai-review:
    runs-on: ubuntu-latest

    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout PR code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          pip install google-generativeai PyGithub

      - name: Save AI script
        run: |
          cat > ai_review.py << 'SCRIPT_END'
          import os
          import sys
          from github import Github, Auth
          import google.generativeai as genai

          print("üîç Running AI Review...")

          # Configure Gemini API
          genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
          
          # List available models (for debugging)
          print("üìã Available models:")
          for m in genai.list_models():
              if 'generateContent' in m.supported_generation_methods:
                  print(f"  - {m.name}")
          
          # Configure GitHub API with new Auth method
          auth = Auth.Token(os.getenv("GITHUB_TOKEN"))
          g = Github(auth=auth)

          # Get PR details
          repo = g.get_repo(os.getenv("REPO_NAME"))
          pr = repo.get_pull(int(os.getenv("PR_NUMBER")))

          # Collect changed code
          changed_code = ""
          file_count = 0
          total_additions = 0
          total_deletions = 0

          for f in pr.get_files():
              file_count += 1
              total_additions += f.additions
              total_deletions += f.deletions
              
              patch = f.patch or ""
              if patch:
                  changed_code += f"### File: {f.filename}\n```diff\n{patch}\n```\n\n"

          # Check if there are changes to review
          if not changed_code:
              print("No code changes to review")
              sys.exit(0)

          # Limit the diff size to avoid token limits (especially important for free tier)
          if len(changed_code) > 20000:  # Reduced limit for free tier
              changed_code = changed_code[:20000] + "\n\n... (diff truncated due to size)"

          prompt = f"""
          You are an expert code reviewer. Review this PR diff and provide feedback.

          Please be concise but thorough. Focus on:
          - üêõ Critical bugs or logic errors
          - üîí Security vulnerabilities
          - ‚ö° Major performance issues
          - üé® Significant code quality problems

          PR Statistics:
          - Files changed: {file_count}
          - Lines added: {total_additions}
          - Lines deleted: {total_deletions}

          PR Diff:
          {changed_code}

          Provide your review in a clear, bulleted format.
          """

          try:
              # Use the correct model for free tier
              # Try different model names based on what's available
              model_names = [
                  "models/gemini-1.5-flash-latest",  # Most likely for free tier
                  "models/gemini-1.5-flash",
                  "models/gemini-1.5-pro-latest",
                  "gemini-1.5-flash-latest",
                  "gemini-1.5-flash",
              ]
              
              model = None
              for model_name in model_names:
                  try:
                      print(f"üîß Trying model: {model_name}")
                      model = genai.GenerativeModel(model_name)
                      # Test if model works
                      test_response = model.generate_content("test")
                      print(f"‚úÖ Using model: {model_name}")
                      break
                  except Exception as e:
                      print(f"  ‚ùå {model_name} failed: {str(e)[:100]}")
                      continue
              
              if model is None:
                  raise Exception("No compatible model found. Please check your API key and available models.")
              
              response = model.generate_content(prompt)
              
              # Format the comment
              comment = f"""### ü§ñ AI Code Review

          **PR Summary:** {file_count} file(s) changed (+{total_additions} / -{total_deletions} lines)

          ---

          {response.text}

          ---

          *This is an automated review by Gemini AI (Free Tier). Please verify suggestions before implementing.*
          """
              
              pr.create_issue_comment(comment)
              print("‚úÖ AI Review posted successfully!")
              
          except Exception as e:
              print(f"‚ùå Error during review: {str(e)}")
              # Post a simple comment if AI review fails
              fallback_comment = f"""### ü§ñ AI Code Review

          Unable to generate AI review at this time.
          
          **PR Summary:** {file_count} file(s) changed (+{total_additions} / -{total_deletions} lines)

          Manual review checklist:
          - [ ] No critical bugs or logic errors
          - [ ] No security vulnerabilities
          - [ ] Performance is acceptable
          - [ ] Code follows project standards
          - [ ] Tests are included/updated
          """
              pr.create_issue_comment(fallback_comment)
              sys.exit(1)
          SCRIPT_END

      - name: Run AI Review Script
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          REPO_NAME: ${{ github.repository }}
        run: python ai_review.py